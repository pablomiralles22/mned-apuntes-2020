\section{Métodos multipaso}

Hasta ahora, al implementar un método de resolución numérica sólo usábamos
$\vw_i$ para calcular $\vw_{i+1}$,
ignorando los valores obtenidos anteriormente.
A pesar de que esto parezca obvio pues si $\vf$ es Lipschitziana
la solución está unívocamente determinada por un punto,
cuando buscamos una solución computacional
los valores pasados pueden ser de utilidad para ahorra cálculos.
Los métodos multipaso se construyen, una vez obtenidos los primeros $m$ pasos,
utilizando los $m$ valores anteriores para calcular el valor $\vw_{i+1}$.

\begin{definition}
    Un \emph{método en diferencias a $m$ pasos} es un método de paso fijo $h$
    que a partir de $m$ estados
    $\{(t_0 + jh, \vw_j) \approx (t_0 + jh, \vy(t_j))\}_{j = i-m+1,\ldots,i-1}$,
    aproxima $\vy(t_i) = \vy(t_0 + ih)$ como
    \begin{equation*}
        \vw_i = a_0\vw_{i-m} + a_1\vw_{i-m+1} + \dots + a_{i-1}\vw_{i-1}
            + h\vphi(h, t_i, \vw_{i-m+1}, \vw_{i-m+2}, \dots, \vw_i).
    \end{equation*}
\end{definition}

Ahora tenemos dos tipos de métodos, pues si $\vphi$ depende de $\vw_i$
será um método implícito y en otro caso será explicito.
En los implícitos tendremos que resolver una ecuación
para calcular el próximo punto.
Dos ejemplos de estos métodos son
el método explícito de Adams-Bashforth de $4$ pasos y
el método implícito de Adams-Moulton de $3$ pasos.
Nótese que si ahora tuvieramos $m = 1$,
tendríamos un método a un paso como hasta ahora.

\begin{method}{Método explícito de Adams-Bashforth de orden $4$}
    \label{met:AB4steps}

    El \emph{método de Adams-Bashforth} de orden $4$
    es un método a $4$ pasos.
    \begin{equation}
        \vw_{i+1} = \vw_i + \frac{h}{24}\qty\bigg[
            55\vf(t_i, \vw_i) - 59\vf(t_{i-1}, \vw_{i-1})
            + 37\vf(t_{i-2}, \vw_{i-2}) - 9\vf(t_{i-3}, \vw_{i-3})
        ].
    \end{equation}
\end{method}

\begin{proposition}
    El método de Adams-Bashforth de orden $4$
    tiene un error local de truncamiento
    de orden $\ELT_{i+1}(h) = \frac{251}{720}\vy^5(\xi)h^4 + \vo(h^5)$.
\end{proposition}

\begin{method}{Método implícito de Adams-Moulton de orden $4$}
    \label{met:AM3steps}

    El \emph{método de Adams-Moulton} de orden $4$
    es un método a $3$ pasos.
    \begin{equation}
        \vw_{i+1} = \vw_i + \frac{h}{24}\qty\bigg[
            9\vf(t_{i+1}, \vw_{i+1}) + 19\vf(t_i, \vw_i)
            - 5\vf(t_{i-1}, \vw_{i-1}) + \vf(t_{i-2}, \vw_{i-2})
        ].
    \end{equation}
\end{method}

\begin{proposition}
    El método de Adams-Bashforth de orden $4$
    tiene un error local de truncamiento
    de orden $\ELT_{i+1}(h) = \frac{19}{720}\vy^5(\xi)h^4 + \vo(h^5)$.
\end{proposition}

Podemos ver que ambos métodos requieren de una única evaluación de $f$
en cada paso y que el \cref{met:AM3steps} tiene un menor ELT pero a cambio
requiere alguna forma de despejar $\vw_{i+1}$.

\begin{remark}
    Resolver la ecuación implicita para $\vw_{i+1}$ no se puede hacer,
    en general, de forma analítica.
\end{remark}

\begin{remark}
    Existen métodos de Adams de diferentes órdenes y se obtienen de
    \begin{equation*}
        \vy'(t) = \vf(t,\vy(t)) \implies
        \vy(t_{i+1}) - \vy(t_i) =
        \int\limits_{t_i}^{t_{i+1}} \vy'(t) \dd{t} =
        \int\limits_{t_i}^{t_{i+1}} \vf(t,\vy(t)) \dd{t}.
    \end{equation*}
    Si quisiésemos aproximar $\vf(t,\vy(t))$ usando un polinomio interpolador
    $\vb{P}(t)$ en los puntos $t_{i-m+1},\dots,t_i$,
    tendríamos
    \begin{equation*}
        \vy(t_{i+1}) \approx
        \vy(t_i) + \int\limits_{t_i}^{t_{i+1}} \vb{P}(t) \dd{t}.
    \end{equation*}
    Por otra parte, los métodos implícitos usan el nodo $(t_{i+1}, \vw_{i+1})$
    a la hora de aproximar la integral.
\end{remark}

\begin{definition}
    Un \emph{método multipaso estándar a $m$ pasos}
    es un método multipaso en diferencias cuya expresión es
    \begin{equation*}
        \vw_{i+1} = a_0\vw_{i-m+1} + \dots + a_{m-1}\vw_i + h[
            b_0\vf(t_{i+1-m},\vw_{i+1-m}) + \dots + b_{m-1}\vf(t_i,\vw_i)
            + b_m\vf(t_{i+1},\vw_{i+1})
        ],
    \end{equation*}
    Si $b_m = 0$ entonces el método es explícito, en otro caso es implícito.
\end{definition}

Para tener disponibles los $m$ primeros $\vw_i$ para un método multipaso,
normalmente se utilizar un método de paso fijo.

\section{Teoría general de Convergencia}

Con los métodos multipaso hay que tener cuidado pues usamos
sucesiones recurrentes de orden mayor que uno,
lo que nos puede dar problemas numéricos
por el mal condicionamiento.
(Independientemente de los problemas de convergencia del propio método.)
Por ello introducimos las siguientes definiciones.

\begin{definition}
    Fijado un intervalo de resolución $[a, b]$,
    un método se dice \emph{consistente} (o \emph{compatible})
    con el PVI que aproxima si
    \begin{equation*}
        \lim\nolimits_{h\to 0} \max_{i = 1,\ldots,n(h)}{\norm{\ELT_i(h)}} = 0.
	\end{equation*}
	El método se dice de orden $p$, $p \geq 1$, si $p$ es el mayor entero
	tal que $\max{\norm*{\ELT_{i+1}(h)}} = \theta(h^p)$.
\end{definition}

Naturalmente solo consideraremos los métodos consistentes y de orden tan
alto como podamos encontrar teniendo un coste razonable.

\begin{definition}
    Fijado un intervalo de resolución $[a, b]$,
    un método en diferencias se dice \emph{convergente} si
    \begin{equation*}
        \lim\nolimits_{h \to 0}
            \max_{i = 1,\ldots,n(h)}{\norm{\vy(t_i)-\vw_i}} = 0.
    \end{equation*}
\end{definition}

Un método convergente nos resuelve el problema en caso de una
implementacion de ``aritmética infinita''.
Lamentablemente solo disponemos de ordenadores de aritmética finita.
Es decir, durante la ejecución en un ordenador se cometen errores de redondeo
que hacen que la solución que calculemos sea
\begin{equation*}
    \tw_{i+1} = \sum_{j=1}^m {a_{j-1}\tw_{i-m+j}}
        + h\vphi(t_i,\tw_{i-m+1}, \dots, \vw_i,\tw_{i+1},h) + \delta_{i+1}
\end{equation*}
para ciertos $\delta_i$, $i = 0,\ldots,n$.
Luego nuestros métodos no son los deseados sino una aproximación de estos.
Por eso, introducimos la noción de método estable.

\begin{definition}
    Un método en diferencias se dice \emph{estable}
    si al generar una segunda solución aproximada de la forma
    \begin{equation*}
        \tw_{i+1} = \sum_{j=1}^m {a_{j-1}\tw_{i-m+j}}
            + h \vphi(t_i,\tw_{i-m+j}, \dots, \tw_i,\tw_{i+1},h)
            + \delta_{i+1},
    \end{equation*}
    existe una constante $M$, independiente de $h$, tal que
    \begin{equation*} \label{stab}
        \max_{m \le i \le n}{\norm{\tw_i - \vw_i}} \le M\qty[
            \max_{0 \le i < m}{\norm{\tw_i - \vw_i}}
            + \sum_{m \le i \le n} \norm{\delta_i}
        ]
    \end{equation*}
\end{definition}

\begin{remark}
    %TODO una referencia estaría increible en vd
    Esto no contradice el \cref{thm:euler-convergence}, pues
    $\sum\norm{\delta_j} \approx n\varepsilon \approx
    \frac{t_n - t_0}{h}\varepsilon$.
\end{remark}

\begin{theorem}
    Si un método en diferencias es estable y consistente,
    entonces es convergente.
    Si, además, es de orden $p \geq 1$, se tiene
    %TODO creo que es h^p
    \begin{equation*}
        \max_{0 \le i \le n}\norm{\tw_i - \vw_i} \le M\qty\bigg[
            \max_{0 \le i < m} \norm{\tw_i - \vw_i} + Kh^p
            ]
    \end{equation*}
    Para constantes adecuadas M y K.
\end{theorem}

\begin{proof}
    Sea $\delta_i = h\ELT_i(h_i)$ y utilicemos la estabilidad con $\tilde{w}_i$.
    Se tiene que
    \begin{equation*}
        \max_{0 \le i \le n}\norm{\tw_i - \vw_i} \le M\qty\bigg[
            \max_{0 \le i < m}\norm{\tw_i - \vw_i}
            + \sum_{m\le i \le n}\norm{\delta_i}
        ]
    \end{equation*}
    para algún $m$. Pero
    \begin{equation*}
        \sum_{m \le i \le n} \norm{\delta_i} =
        \sum_{m \le i \le n} h\norm{\ELT_i(h)} \le
        \qty(\sum_{m \le i \le n} h)
            \max_{m \le i \le n}\norm{\ELT_i(h)} \le
        (b-a)\max_{m \le i \le n}\norm{\ELT_i(h)},
    \end{equation*}
    donde esta última tiende a $0$ cunado $h$ tiende a $0$
    por la condición de consistencia.
    Si además $\max_i\norm{\ELT_i(h)} = O(h^p)$,
    $\max_i\norm{\ELT_i(h)} \le \frac{Kh^p}{b-a}$ para algún $K$,
    y de ahí el resultado.
\end{proof}

%TODO este teorema está fatal hay que mirarlo en el burden
\begin{theorem}
    Sea $\vw_{i+1} = \vw_i + h\vphi(h, t_i, \vw_i)$ un método a un paso tal que
    $\vphi(h, t_i, \vw_i)$ es continua y lipschitziana en $\vw_i$.
    Entonces existe $h_0 > 0$ tal que para todo $h < h_0$,
    \begin{enumerate}
        \item El método es estable
        \item El método es convergente si es consistente,
        lo que ocurre si $\vphi(0, t, \vy) = \vf(t, \vy(t))$ para todo $t$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Sea $L$ la constante de lipschitz de $\vphi$ y
    sean $\vw_{i+1} = \vw_i + h\vphi(h, t_i, \vw_i)$ y
    $\tw_{i+1} = \tw_i + h\vphi(h, t_i, \tw_i) + \delta_i$.
    Entonces
    \begin{align*}
        \norm{\tw_{i+1} - \vw_{i+1}} & {} \le
            (1 + hL)\norm{\tw_i - \vw_i} + \norm{\delta_i} \\
        & \le (1 + hL)^2\norm{\tw_{i-1} - \vw_{i-1}}
            + (1 + hL)\norm{\delta_{i-1}}
            + \norm{\delta_i} \le \ldots \\
        \ldots & \le (1 + hL)^{i+1}\norm{\tw_0 - \vw_0} + \qty[
            \norm{\delta_i} + (1 + hL)\norm{\delta_{i-1}} + \dots
            + (1 + hL)^i\norm{\delta_1}
        ] \\
        & \le (1 + hL)^{i+1}\qty(
            \norm{\tw_0 - \vw_0} + \sum_{j=1}^i \norm{\delta_j}
        ) \\
        & \le \nume^{(i+1)hL}\qty(
            \norm{\tw_0 - \vw_0} + \sum_{j=1}^i \norm{\delta_j}
        ) \\
        & \le \, \nume^{(b-a)L} \; \qty(
            \norm{\tw_0 - \vw_0} + \sum_{j=1}^i \norm{\delta_j}
        ),
    \end{align*}
    donde $[a, b]$ es el intervalo de resolución.
    Lo que demuestra que el método es estable.

    Estudiamos ahora el error local de truncamiento.
    \begin{multline*}
        \ELT_i(h) = \frac{\vy(t_i + h) - \vy(t_i)}{h} - \vphi(h, t_i, \vy(t_i)) =
        \vy'(\xi_i) - \vphi(h, t_i, \vy(t_i)) = \\
        \vf(\xi_i, \vy(\xi_i)) - \vphi(h, t_i, \vy(t_i)) =
        \vf(\xi_i, \vy(\xi_i)) - \vphi(0, \xi_i, \vy(\xi_i))
            + \vphi(0, \xi_i, \vy(\xi_i)) - \vphi(h, t_i, \vy(t_i)).
    \end{multline*}
    Por la continuidad uniforme de la función
    $(t, h) \mapsto \vphi(h, t, \vy(t))$ sobre $[a, b] \times [0, h_0]$,
    dado $\varepsilon > 0$ existe $h_0 > 0$ tal que si $h < h_0$,
    entonces como $\abs{\xi_i - t_i} < h$,
    \begin{equation*}
        \norm{\vphi(0, \xi_i, \vy(\xi_i)) - \vphi(h, t_i, \vy(t_i))} <
        \varepsilon.
    \end{equation*}
    Por tanto, $\lim_{h \to 0} \ELT_i(h) = 0$
    si $\vf(t_i, \vy(t_i)) = \vphi(0, t_i, \vy(t_i))$.
\end{proof}

\subsection{Estudio de la estabilidad para métodos multipaso}

Estudiar la estabilidad de los métodos a $m$ pasos es más complicado.
Nosotros la estudiaremos sabiendo que, en realidad,
para estudiar la estabilidad basta hacerlo con el problema
$y' = 0$, $y(0) = \alpha \in \R$,
pero la demostración de este hecho no forma parte de estos apuntes.

Dado un método multipaso estándar a $m$ pasos,
\begin{equation*}
    \vw_i = a_0\vw_{i-m} + \dots + a_{m-1}\vw_{i-1} + h\qty\bigg[
        b_0\vf(t_{i-m}, \vw_{i-m}) + \dots + b_{m-1}\vf(t_{i-1}, \vw_{i-1})
        + b_m\vf(t_i, \vw_i)
    ]
\end{equation*}
el siguiente punto para el problema de prueba con $y' = f = 0$ se calcularía
siguiendo la ecuación de recurrencia
\begin{equation*}
    w_i = a_0w_{i-m} + \dots + a_{m-1}w_{i-1},
\end{equation*}
cuyo polinomio característico tiene raíces que satisfacen
\begin{equation*}
    z^m = a_0 + \dots + a_{m-1}z^{m-1}.
\end{equation*}
Si todas las raíces reales, $\lambda_1,\dots,\lambda_n$, fuesen distintas,
la ecuación general sería
\begin{equation*}
    w_n = \sum_{j=1}^m c_j\lambda_j^n
\end{equation*}
con los $c_j$ en función de $m$ puntos iniciales.

Lo primero que podemos afirmar es que como $y(t) = \alpha$ es una solución,
si el método tiene error local de truncamiento $o(h^p)$, $p \ge 1$,
$w_n = \alpha$ debe ser una posible solución.
\begin{equation*}
    \alpha = w_i =
    a_0w_{i-m} + a_1w_{i-m+1} + \dots + a_{m-1}w_{i-1} =
    a_0\alpha + a_1\alpha + \dots + a_{m-1}\alpha \iff
    \sum_{i = 0}^{m-1} a_i = 1 \iff
    \text{$1$ es raíz.}
\end{equation*}
Es decir, $\lambda = 1$ es una de las raíces del polinomio caracerístico.
por lo que las soluciones son de la forma
\begin{equation*}
    w_n = c_1 + \sum_{j=2}^m c_j\lambda_j^n,
\end{equation*}
y para nuestra ecuación de prueba sería $c_1 = \alpha$,
$c_j = 0$ para todo $j = 2,\ldots,m$.

Para estudiar la estabilidad,
nos interesa que acotando los errores de redondeo en las condiciones iniciales
se acoten también los errores en la solución calculada.
Eso motiva la siguiente definición.

\begin{definition}
    Sean $\lambda_1,\ldots,\lambda_n$ las $n$ raíces del
    polinomio característico
    \begin{equation*}
        \lambda^m - a_{m-1}z^{m-1} - a_{m-2}z^{m-2} - \dots - a_0
    \end{equation*}
    de un método a $m$ pasos
    \begin{equation}\label{eqn:multistep}
        \vw_{i+1} = a_0\vw_{i-m+1} + a_1w{i-m+2} + \dots + a_{m-1}\vw_i
            + h_i\vphi(t_i,\vw_{i-m+1},w{i-m+2},\dots,\vw_i).
    \end{equation}
    El método cumple la \emph{condición de raíz} si
    $\abs{\lambda_i} \le 1$ para todo $i = 1,\ldots, m$
    %TODO este tipo de añadidos que son necesarios si no asumimos todas distintas
    % hay que ver si los quitamos porque con Esquembre no lo hemos visto
    % pero especificamos que lo hemos quitado
    % o si lo dejamos y lo marcamos con otro color por ejemplo
    % o si lo quitamos
    y todas las raíces de valor absoluto uno son simples.
\end{definition}

\begin{theorem}
    Un método multipaso es estable si y solo si cumple la condición de raíz.
    Además, si el método es consistente,
    que sea estable es equivalente a que sea convergente.
\end{theorem}

