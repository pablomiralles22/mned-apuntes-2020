\section{Teoría general de Convergencia}

Con los métodos multipaso hay que tener cuidado pues usamos
sucesiones recurrentes de orden mayor que uno,
lo que nos puede dar problemas numéricos
por el mal condicionamiento.
(Independientemente de los problemas de convergencia del propio método.)
Por ello introducimos las siguientes definiciones.

\begin{definition}
    Fijado un intervalo de resolución $[a, b]$,
    un método se dice \emph{consistente} (o \emph{compatible})
    con el PVI que aproxima si
    \begin{equation*}
        \lim\nolimits_{h\to 0} \max_{i = 1,\ldots,n(h)}{\norm{\ELT_i(h)}} = 0.
	\end{equation*}
	El método se dice de orden $p$, $p \geq 1$, si $p$ es el mayor entero
	tal que $\max{\norm*{\ELT_{i+1}(h)}} = \vo(h^p)$.
\end{definition}

Naturalmente solo consideraremos los métodos consistentes y de orden tan
alto como podamos encontrar teniendo un coste razonable.

\begin{definition}
    Fijado un intervalo de resolución $[a, b]$,
    un método en diferencias se dice \emph{convergente} si
    \begin{equation*}
        \lim\nolimits_{h \to 0}
            \max_{i = 1,\ldots,n(h)}{\norm{\vy(t_i)-\vw_i}} = 0.
    \end{equation*}
\end{definition}

Un método convergente nos resuelve el problema en caso de una
implementacion de ``aritmética infinita''.
Lamentablemente solo disponemos de ordenadores de aritmética finita.
Es decir, durante la ejecución en un ordenador se cometen errores de redondeo
que hacen que la solución que calculemos sea
\begin{equation*}
    \tw_i = \sum_{j=0}^{m-1} {a_j\tw_{i-m+j}}
        + h\vphi(h, t_i, \tw_{i-m}, \dots, \vw_{i-1}, \tw_i) + \delta_{i+1}
\end{equation*}
para ciertos $\delta_i$, $i = 0,\ldots,n$.
Luego nuestros métodos no son los deseados sino una aproximación de estos.
Por eso, introducimos la noción de método estable.

\begin{definition}
    Un método en diferencias se dice \emph{estable}
    si al generar una segunda solución aproximada de la forma
    \begin{equation*}
        \tw_i = \sum_{j=0}^{m-1} {a_j\tw_{i-m+j}}
            + h\vphi(h, t_i, \tw_{i-m}, \dots, \tw_{i-1}, \tw_i) + \delta_{i+1},
    \end{equation*}
    existe una constante $M$, independiente de $h$, tal que
    \begin{equation*} \label{stab}
        \max_{m \le i \le n}{\norm{\tw_i - \vw_i}} \le M\qty[
            \max_{0 \le i < m}{\norm{\tw_i - \vw_i}}
            + \sum_{m \le i \le n} \norm{\delta_i}
        ]
    \end{equation*}
\end{definition}

\begin{remark}
    %TODO una referencia estaría increible en vd
    Esto no contradice el \cref{thm:euler-convergence}, pues
    $\sum\norm{\delta_j} \approx n\varepsilon \approx
    \frac{t_n - t_0}{h}\varepsilon$.
\end{remark}

\begin{theorem}
    Si un método en diferencias es estable y consistente,
    entonces es convergente.
    Si, además, es de orden $p \geq 1$, se tiene
    %TODO creo que es h^p
    \begin{equation*}
        \max_{0 \le i \le n}\norm{\tw_i - \vw_i} \le M\qty\bigg[
            \max_{0 \le i < m} \norm{\tw_i - \vw_i} + Kh^p
            ]
    \end{equation*}
    Para constantes adecuadas M y K.
\end{theorem}

\begin{proof}
    Si aplicamos la definición de estabilidad con $\delta_i = h\ELT_i(h_i)$,
    para que se cumpla que $\tw_i = \vy(t_i)$,
    tenemos que
    \begin{equation*}
        \max_{0 \le i \le n}\norm{\vy(t_i) - \vw_i} =
        \max_{0 \le i \le n}\norm{\tw_i - \vw_i} \le
        M\qty\bigg[
            \max_{0 \le i < m}\norm{\tw_i - \vw_i}
            + \sum_{m\le i \le n}\norm{\delta_i}
        ]
    \end{equation*}
    para algún $m$. Pero
    \begin{equation*}
        \sum_{m \le i \le n} \norm{\delta_i} =
        \sum_{m \le i \le n} h\norm{\ELT_i(h)} \le
        \qty(\sum_{m \le i \le n} h)
            \max_{m \le i \le n}\norm{\ELT_i(h)} \le
        (b-a)\max_{m \le i \le n}\norm{\ELT_i(h)},
    \end{equation*}
    donde esta última tiende a $0$ cuando $h$ tiende a $0$
    por la condición de consistencia.
    Por tanto, si el error en los $m$ primeros pasos es $0$ o
    el método de paso fijo que utilicemos para calcularlos
    es también estable y consistente,
    el resultado es convergente.
    Si además $\max_i\norm{\ELT_i(h)} = \vo(h^p)$,
    y el método multipaso también es de orden $\vo(h^p)$,
    $\max_i\norm{\ELT_i(h)} \le \frac{Kh^p}{b-a}$ para algún $K$,
    y de ahí el resultado.
\end{proof}

%TODO este teorema está fatal hay que mirarlo en el burden
\begin{theorem}
    Sea $\vw_{i+1} = \vw_i + h\vphi(h, t_i, \vw_i)$ un método a un paso tal que
    $\vphi(h, t_i, \vw_i)$ es continua y lipschitziana en $\vw_i$.
    Entonces existe $h_0 > 0$ tal que para todo $h < h_0$,
    \begin{enumerate}
        \item El método es estable
        \item El método es convergente si es consistente,
        lo que ocurre si $\vphi(0, t, \vy) = \vf(t, \vy(t))$ para todo $t$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    Sea $L$ la constante de lipschitz de $\vphi$ y
    sean $\vw_{i+1} = \vw_i + h\vphi(h, t_i, \vw_i)$ y
    $\tw_{i+1} = \tw_i + h\vphi(h, t_i, \tw_i) + \delta_i$.
    Entonces
    \begin{align*}
        \norm{\tw_{i+1} - \vw_{i+1}} & {} \le
            (1 + hL)\norm{\tw_i - \vw_i} + \norm{\delta_{i+1}} \\
        & \le (1 + hL)^2\norm{\tw_{i-1} - \vw_{i-1}}
            + (1 + hL)\norm{\delta_i}
            + \norm{\delta_{i+1}} \le \ldots \\
        \ldots & \le (1 + hL)^{i+1}\norm{\tw_0 - \vw_0} + \qty[
            \norm{\delta_{i+1}} + (1 + hL)\norm{\delta_i} + \dots
            + (1 + hL)^i\norm{\delta_1}
        ] \\
        & \le (1 + hL)^{i+1}\qty(
            \norm{\tw_0 - \vw_0} + \sum_{j=1}^{i+1} \norm{\delta_j}
        ) \\
        & \le \nume^{(i+1)hL}\qty(
            \norm{\tw_0 - \vw_0} + \sum_{j=1}^{i+1} \norm{\delta_j}
        ) \\
        & \le \, \nume^{(b-a)L} \; \qty(
            \norm{\tw_0 - \vw_0} + \sum_{j=1}^n \norm{\delta_j}
        ),
    \end{align*}
    donde $[a, b]$ es el intervalo de resolución.
    Lo que demuestra que el método es estable.

    Estudiamos ahora el error local de truncamiento.
    \begin{multline*}
        \ELT_i(h) = \frac{\vy(t_i + h) - \vy(t_i)}{h} - \vphi(h, t_i, \vy(t_i)) =
        \vy'(\xi_i) - \vphi(h, t_i, \vy(t_i)) = \\
        \vf(\xi_i, \vy(\xi_i)) - \vphi(h, t_i, \vy(t_i)) =
        \vf(\xi_i, \vy(\xi_i)) - \vphi(0, \xi_i, \vy(\xi_i))
            + \vphi(0, \xi_i, \vy(\xi_i)) - \vphi(h, t_i, \vy(t_i)).
    \end{multline*}
    Por la continuidad uniforme de la función
    $(t, h) \mapsto \vphi(h, t, \vy(t))$ sobre $[a, b] \times [0, h_0]$,
    dado $\varepsilon > 0$ existe $h_0 > 0$ tal que si $h < h_0$,
    entonces como $\abs{\xi_i - t_i} < h$,
    \begin{equation*}
        \norm{\vphi(0, \xi_i, \vy(\xi_i)) - \vphi(h, t_i, \vy(t_i))} <
        \varepsilon.
    \end{equation*}
    Por tanto, $\lim_{h \to 0} \ELT_i(h) = 0$
    si $\vf(t, \vy(t)) = \vphi(0, t, \vy(t))$ para todo $t$.
\end{proof}

\subsection{Estudio de la estabilidad para métodos multipaso}

Estudiar la estabilidad de los métodos a $m$ pasos es más complicado.
Nosotros la estudiaremos sabiendo que, en realidad,
para estudiar la estabilidad basta hacerlo con el problema
$y' = 0$, $y(0) = \alpha \in \R$,
pero la demostración de este hecho no forma parte de estos apuntes.

Dado un método multipaso estándar a $m$ pasos,
\begin{equation*}
    \vw_i = a_0\vw_{i-m} + \dots + a_{m-1}\vw_{i-1} + h\qty\bigg[
        b_0\vf(t_{i-m}, \vw_{i-m}) + \dots + b_{m-1}\vf(t_{i-1}, \vw_{i-1})
        + b_m\vf(t_i, \vw_i)
    ]
\end{equation*}
el siguiente punto para el problema de prueba con $y' = f = 0$ se calcularía
siguiendo la ecuación de recurrencia
\begin{equation*}
    w_i = a_0w_{i-m} + \dots + a_{m-1}w_{i-1},
\end{equation*}
cuyo polinomio característico tiene raíces que satisfacen
\begin{equation*}
    z^m = a_0 + \dots + a_{m-1}z^{m-1}.
\end{equation*}
Si todas las raíces reales, $\lambda_1,\dots,\lambda_n$, fuesen distintas,
la ecuación general sería
\begin{equation*}
    w_n = \sum_{j=1}^m c_j\lambda_j^n
\end{equation*}
con los $c_j$ en función de $m$ puntos iniciales.

Lo primero que podemos afirmar es que como $y(t) = \alpha$ es una solución,
si el método tiene error local de truncamiento $\vo(h^p)$, $p \ge 1$,
$w_n = \alpha$ debe ser una posible solución.
\begin{equation*}
    \alpha = w_i =
    a_0w_{i-m} + a_1w_{i-m+1} + \dots + a_{m-1}w_{i-1} =
    a_0\alpha + a_1\alpha + \dots + a_{m-1}\alpha \iff
    \sum_{i = 0}^{m-1} a_i = 1 \iff
    \text{$1$ es raíz.}
\end{equation*}
Es decir, $\lambda = 1$ es una de las raíces del polinomio caracerístico.
por lo que las soluciones son de la forma
\begin{equation*}
    w_n = c_1 + \sum_{j=2}^m c_j\lambda_j^n,
\end{equation*}
y para nuestra ecuación de prueba sería $c_1 = \alpha$,
$c_j = 0$ para todo $j = 2,\ldots,m$.

Para estudiar la estabilidad,
nos interesa que acotando los errores de redondeo en las condiciones iniciales
se acoten también los errores en la solución calculada.
Eso motiva la siguiente definición.

\begin{definition}
    Sean $\lambda_1,\ldots,\lambda_n$ las $n$ raíces del
    polinomio característico
    \begin{equation*}
        \lambda^m - a_{m-1}z^{m-1} - a_{m-2}z^{m-2} - \dots - a_0
    \end{equation*}
    de un método a $m$ pasos
    \begin{equation}\label{eqn:multistep}
        \vw_{i+1} = a_0\vw_{i-m+1} + a_1w{i-m+2} + \dots + a_{m-1}\vw_i
            + h_i\vphi(t_i,\vw_{i-m+1},w{i-m+2},\dots,\vw_i).
    \end{equation}
    El método cumple la \emph{condición de raíz} si
    $\abs{\lambda_i} \le 1$ para todo $i = 1,\ldots, m$
    %TODO este tipo de añadidos que son necesarios si no asumimos todas distintas
    % hay que ver si los quitamos porque con Esquembre no lo hemos visto
    % pero especificamos que lo hemos quitado
    % o si lo dejamos y lo marcamos con otro color por ejemplo
    % o si lo quitamos
    y todas las raíces de valor absoluto uno son simples.
\end{definition}

\begin{theorem}
    Un método multipaso es estable si y solo si cumple la condición de raíz.
    Además, si el método es consistente,
    que sea estable es equivalente a que sea convergente.
\end{theorem}

